{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2430,
   "id": "39f8c066-2b2d-4993-83d8-ffe1fa350d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/divit/anaconda3/lib/python3.12/site-packages (3.0.2)\n",
      "Requirement already satisfied: lightgbm in /home/divit/anaconda3/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: catboost in /home/divit/anaconda3/lib/python3.12/site-packages (1.2.8)\n",
      "Requirement already satisfied: numpy in /home/divit/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/divit/anaconda3/lib/python3.12/site-packages (from xgboost) (2.21.5)\n",
      "Requirement already satisfied: scipy in /home/divit/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n",
      "Requirement already satisfied: graphviz in /home/divit/anaconda3/lib/python3.12/site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in /home/divit/anaconda3/lib/python3.12/site-packages (from catboost) (3.10.0)\n",
      "Requirement already satisfied: pandas>=0.24 in /home/divit/anaconda3/lib/python3.12/site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: plotly in /home/divit/anaconda3/lib/python3.12/site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in /home/divit/anaconda3/lib/python3.12/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/divit/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/divit/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/divit/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/divit/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/divit/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/divit/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/divit/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/divit/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/divit/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/divit/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/divit/anaconda3/lib/python3.12/site-packages (from plotly->catboost) (8.2.3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "!pip install xgboost lightgbm catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2431,
   "id": "f26d9634-f4a1-46dc-88df-ab2ef7e535ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df=pd.read_csv(\"Train_Data.csv\")\n",
    "test_df=pd.read_csv(\"Test_Data.csv\")\n",
    "cat_cols=['RIAGENDR','PAQ605','DIQ010']\n",
    "num_cols=['BMXBMI','LBXGLU','LBXGLT','LBXIN','insulin_glucose_ratio','BMI_glucose_ratio']\n",
    "new_features=[]\n",
    "target_col=['age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2434,
   "id": "51f925bc-d087-4970-a005-51434e740e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering on raw_df\n",
    "# raw_df[\"glucose_risk\"] = ((raw_df[\"LBXGLU\"] > 125) | (raw_df[\"LBXGLT\"] > 140)).astype(int)\n",
    "raw_df[\"insulin_glucose_ratio\"] = raw_df[\"LBXIN\"] / (raw_df[\"LBXGLU\"] + 1)\n",
    "# raw_df[\"high_bmi\"] = (raw_df[\"BMXBMI\"] > 30).astype(int)\n",
    "\n",
    "# Same on test_df\n",
    "# test_df[\"glucose_risk\"] = ((test_df[\"LBXGLU\"] > 125) | (test_df[\"LBXGLT\"] > 140)).astype(int)\n",
    "test_df[\"insulin_glucose_ratio\"] = test_df[\"LBXIN\"] / (test_df[\"LBXGLU\"] + 1)\n",
    "# test_df[\"high_bmi\"] = (test_df[\"BMXBMI\"] > 30).astype(int)\n",
    "raw_df['BMI_glucose_ratio'] = raw_df['BMXBMI'] / (raw_df['LBXGLU'] + 1)\n",
    "# raw_df['insulin_times_glucose'] = raw_df['LBXIN'] * raw_df['LBXGLU']\n",
    "test_df['BMI_glucose_ratio'] = test_df['BMXBMI'] / (test_df['LBXGLU'] + 1)\n",
    "# test_df['insulin_times_glucose'] = test_df['LBXIN'] * test_df['LBXGLU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2436,
   "id": "ae390d35-23a2-40fb-b033-419f2d6f7346",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = raw_df.dropna(subset=['age_group'])\n",
    "raw_df = raw_df[raw_df['PAQ605'] != 7]\n",
    "df=raw_df[cat_cols+num_cols+new_features]\n",
    "test_df=test_df[cat_cols+num_cols+new_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2438,
   "id": "d906e97b-30f6-4bcc-ab16-c8a788a8c9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "target=raw_df['age_group']\n",
    "train_data,val_data,train_y,val_y=train_test_split(df,target,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2440,
   "id": "dec33c5f-34a7-41c2-b96d-4a7646a40798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Impute categorical separately\n",
    "mode_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "train_data[cat_cols] = mode_imputer.fit_transform(train_data[cat_cols])\n",
    "val_data[cat_cols] = mode_imputer.transform(val_data[cat_cols])\n",
    "test_df[cat_cols] = mode_imputer.transform(test_df[cat_cols])\n",
    "\n",
    "# 2. Gender-wise KNN imputation function\n",
    "def genderwise_knn_impute(df, num_cols, n_neighbors=3):\n",
    "    df_imputed = df.copy()\n",
    "    for gender in df['RIAGENDR'].unique():\n",
    "        subset = df[df['RIAGENDR'] == gender]\n",
    "        \n",
    "        # Scale only this gender subset\n",
    "        scaler = StandardScaler()\n",
    "        scaled = scaler.fit_transform(subset[num_cols])\n",
    "        \n",
    "        # Apply KNN\n",
    "        knn_imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "        imputed = knn_imputer.fit_transform(scaled)\n",
    "        \n",
    "        # Inverse scale back to original values\n",
    "        unscaled = scaler.inverse_transform(imputed)\n",
    "        df_imputed.loc[subset.index, num_cols] = unscaled\n",
    "        \n",
    "    return df_imputed\n",
    "\n",
    "# 3. Apply to all datasets\n",
    "train_data = genderwise_knn_impute(train_data, num_cols)\n",
    "val_data = genderwise_knn_impute(val_data, num_cols)\n",
    "test_df = genderwise_knn_impute(test_df, num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2400,
   "id": "990be4f9-b88a-4d2a-8216-e6ac3d8bb029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# smote = SMOTE(random_state=42)\n",
    "# train_data, train_y = smote.fit_resample(train_data, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2402,
   "id": "84ee4604-a2ae-41f5-b69d-4b1564593b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# encoder=LabelEncoder()\n",
    "# train_y=encoder.fit_transform(train_y)\n",
    "# val_y=encoder.transform(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2326,
   "id": "afb2bdf5-883e-4086-bb65-f0d9af198c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2404,
   "id": "efb53f23-1add-4485-8c41-466f866d9123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# import pandas as pd\n",
    "# cat_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# cat_encoder.fit(train_data[cat_cols])\n",
    "# encoded_list=list(cat_encoder.get_feature_names_out(cat_cols))\n",
    "# train_data[encoded_list]=cat_encoder.transform(train_data[cat_cols])\n",
    "# val_data[encoded_list]=cat_encoder.transform(val_data[cat_cols])\n",
    "# test_df[encoded_list]=cat_encoder.transform(test_df[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2406,
   "id": "af1cc218-e0b1-4687-99d2-25b181e04763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = train_data.drop(columns=cat_cols)\n",
    "# val_data = val_data.drop(columns=cat_cols)\n",
    "# test_df = test_df.drop(columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2426,
   "id": "5e21308c-d428-4c9d-a399-962d583ba2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler=StandardScaler()\n",
    "# train_data=scaler.fit_transform(train_data)\n",
    "# val_data=scaler.transform(val_data)\n",
    "# test_df=scaler.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2442,
   "id": "5afdda50-ece7-4a1f-a2bd-a19c49790073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier,RandomForestClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# xgb=XGBClassifier(\n",
    "#     n_estimators=700,\n",
    "#     learning_rate=0.02,\n",
    "#     scale_pos_weight=6,\n",
    "#     max_depth=7)\n",
    "# xgb.fit(train_data,train_y)\n",
    "# pred=xgb.predict(val_data)\n",
    "# print(accuracy_score(val_y,pred))\n",
    "# print(classification_report(val_y,pred))\n",
    "# # rf=DecisionTreeClassifier(\n",
    "# #     max_depth=8,\n",
    "# #     random_state=42\n",
    "# # )\n",
    "# # rf.fit(train_data,train_y)\n",
    "# # pred=rf.predict(val_data)\n",
    "# # print(accuracy_score(val_y,pred))\n",
    "# # print(classification_report(val_y,pred))\n",
    "# # # # Define and train the model\n",
    "# # lgbm = LGBMClassifier(\n",
    "# #     n_estimators=500,\n",
    "# #     learning_rate=0.05,\n",
    "# #     max_depth=12,\n",
    "# #     random_state=42\n",
    "# # )\n",
    "\n",
    "# # lgbm.fit(train_data, train_y)\n",
    "\n",
    "# # # Make predictions\n",
    "# # pred = lgbm.predict(val_data)\n",
    "\n",
    "# # # Evaluate\n",
    "# # print(\"Accuracy:\", accuracy_score(val_y, pred))\n",
    "# # print(classification_report(val_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2444,
   "id": "295d07bb-0f0a-4b2a-a898-5bcb4a0e23a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Adult       0.90      0.85      0.87       327\n",
      "      Senior       0.40      0.52      0.45        64\n",
      "\n",
      "    accuracy                           0.80       391\n",
      "   macro avg       0.65      0.68      0.66       391\n",
      "weighted avg       0.82      0.80      0.81       391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Ensure categorical columns are integers\n",
    "for col in cat_cols + new_features:\n",
    "    train_data[col] = train_data[col].astype(int)\n",
    "    val_data[col] = val_data[col].astype(int)\n",
    "    test_df[col]=test_df[col].astype(int)\n",
    "categorical_indices=[0,1,2]\n",
    "model = CatBoostClassifier(\n",
    "        iterations=700,\n",
    "        learning_rate=0.02,\n",
    "        depth=7,\n",
    "        class_weights=[3,10],\n",
    "        cat_features=categorical_indices,\n",
    "        verbose=0,\n",
    "        l2_leaf_reg=3,\n",
    "        random_state=42\n",
    "    )\n",
    "model.fit(train_data, train_y, eval_set=(val_data, val_y), use_best_model=True)\n",
    "print(classification_report(val_y,model.predict(val_data)))\n",
    "# precision    recall  f1-score   support\n",
    "\n",
    "#        Adult       0.89      0.87      0.88       327\n",
    "#       Senior       0.39      0.44      0.41        64\n",
    "\n",
    "#     accuracy                           0.80       391\n",
    "#    macro avg       0.64      0.65      0.64       391\n",
    "# weighted avg       0.81      0.80      0.80       391\n",
    "#   precision    recall  f1-score   support\n",
    "\n",
    "#        Adult       0.90      0.85      0.87       327\n",
    "#       Senior       0.40      0.52      0.45        64\n",
    "\n",
    "#     accuracy                           0.80       391\n",
    "#    macro avg       0.65      0.68      0.66       391\n",
    "# weighted avg       0.82      0.80      0.81       391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2224,
   "id": "cee7e75f-0730-4f72-962d-cf7daed7b681",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Adult       0.88      0.85      0.86       327\n",
      "      Senior       0.34      0.41      0.37        64\n",
      "\n",
      "    accuracy                           0.77       391\n",
      "   macro avg       0.61      0.63      0.62       391\n",
      "weighted avg       0.79      0.77      0.78       391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "top_features = [\n",
    "    'LBXGLT',     # 19.77\n",
    "    'BMXBMI',     # 18.56\n",
    "    'insulin_glucose_ratio',  # 12.80\n",
    "    'LBXGLU',     # 12.74\n",
    "    'PAQ605',     # 10.91\n",
    "    'LBXIN'       # 10.88\n",
    "]\n",
    "\n",
    "# Filter datasets to only top 6 features\n",
    "train_top6 = train_data[top_features]\n",
    "val_top6 = val_data[top_features]\n",
    "\n",
    "# If any of these features are categorical, update their indices\n",
    "\n",
    "# Define model\n",
    "model_top6 = CatBoostClassifier(\n",
    "        iterations=700,\n",
    "        learning_rate=0.03,\n",
    "        depth=6,\n",
    "        class_weights=[3,10],\n",
    "        verbose=0,\n",
    "        random_state=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "model_top6.fit(train_top6, train_y, eval_set=(val_top6, val_y), use_best_model=True)\n",
    "\n",
    "# Evaluate\n",
    "preds = model_top6.predict(val_top6)\n",
    "print(classification_report(val_y, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2446,
   "id": "d95b1a76-4be8-4662-b156-6556b5937146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Feature  Importance\n",
      "5                 LBXGLT   23.720917\n",
      "4                 LBXGLU   12.319211\n",
      "3                 BMXBMI   12.135905\n",
      "1                 PAQ605   11.704549\n",
      "8      BMI_glucose_ratio   11.217565\n",
      "6                  LBXIN   10.774151\n",
      "7  insulin_glucose_ratio   10.299347\n",
      "2                 DIQ010    4.090423\n",
      "0               RIAGENDR    3.737933\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# Get feature names (as list, assuming you're using a DataFrame as input)\n",
    "feature_names = train_data.columns\n",
    "\n",
    "# Combine into a DataFrame for easier viewing\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importance\n",
    "})\n",
    "\n",
    "# Sort by importance (descending)\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print\n",
    "print(importances_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1482,
   "id": "b15e834c-b28a-4bad-87cc-4adef96598b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# less_important = ['LBXGLU', 'PAQ605', 'DIQ010']  # double check column names\n",
    "\n",
    "# train_data_reduced = train_data.drop(columns=less_important)\n",
    "# val_data_reduced = val_data.drop(columns=less_important)\n",
    "\n",
    "# model_reduced = CatBoostClassifier(\n",
    "#     iterations=500,\n",
    "#     learning_rate=0.01,\n",
    "#     depth=5,\n",
    "#     class_weights=[1,5],\n",
    "#     cat_features=[train_data_reduced.columns.get_loc(col) for col in cat_cols if col in train_data_reduced.columns],\n",
    "#     verbose=0,\n",
    "#     random_strength=0.6,  # adds noise to avoid overfitting\n",
    "#     feature_border_type='MinEntropy',\n",
    "#     random_state=42\n",
    "# )\n",
    "# model_reduced.fit(train_data_reduced, train_y, eval_set=(val_data_reduced, val_y), use_best_model=True)\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(val_y, model_reduced.predict(val_data_reduced)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2334,
   "id": "bee01d00-3577-4078-9c3c-61107b428d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict_proba(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2336,
   "id": "43690ba1-0009-4faa-a997-23a2adb74fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/312 predictions are near 50% → potentially confused.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get probability for class 1 (Senior)\n",
    "senior_probs = probs[:, 1]\n",
    "\n",
    "# Count how many are close to 0.5\n",
    "confused_count = np.sum((senior_probs > 0.45) & (senior_probs < 0.55))\n",
    "total = len(senior_probs)\n",
    "print(f\"{confused_count}/{total} predictions are near 50% → potentially confused.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2338,
   "id": "12be0558-358e-4920-a003-2c0570ae4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred=model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2340,
   "id": "4693f7a0-e45d-4658-b63b-2b669ae4013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\"Adult\": 0, \"Senior\": 1}\n",
    "test_pred = pd.Series(test_pred).map(label_map).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2342,
   "id": "78c444a2-807d-4474-b594-1ce2960a580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"age_group\": test_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2344,
   "id": "839c69f0-a6c3-41af-8d01-adc3612ac1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 2344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2346,
   "id": "7ff76c19-88f0-471a-a713-caeca2f0f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2482,
   "id": "57e4e83f-813c-40b5-a737-d0fca10b8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and val\n",
    "full_X = pd.concat([train_data, val_data], axis=0)\n",
    "full_y = pd.concat([train_y, val_y], axis=0)\n",
    "\n",
    "# Ensure same preprocessing (imputation, scaling, etc.)\n",
    "# If already done before combining, skip this.\n",
    "\n",
    "# Train the final model\n",
    "final_model = CatBoostClassifier(\n",
    "        iterations=400,\n",
    "        learning_rate=0.05,\n",
    "        depth=5,\n",
    "        class_weights=[3,10],\n",
    "        cat_features=categorical_indices,\n",
    "        verbose=0,\n",
    "        random_strength=0.5,\n",
    "        l2_leaf_reg=3,\n",
    "        random_state=42\n",
    ")\n",
    "\n",
    "final_model.fit(full_X, full_y)\n",
    "\n",
    "# Final prediction\n",
    "final_preds = final_model.predict(test_df)\n",
    "final_preds = pd.Series(final_preds).map(label_map).values\n",
    "# Optional: Save final predictions\n",
    "submission = pd.DataFrame({\n",
    "    \"age_group\": final_preds\n",
    "})\n",
    "submission.to_csv('final_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2483,
   "id": "c4b4f45f-e902-4cf5-a661-3d63c26b90be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Adult       0.97      0.93      0.95      1637\n",
      "      Senior       0.71      0.86      0.78       314\n",
      "\n",
      "    accuracy                           0.92      1951\n",
      "   macro avg       0.84      0.90      0.87      1951\n",
      "weighted avg       0.93      0.92      0.92      1951\n",
      "\n",
      "[[0.78151791 0.21848209]\n",
      " [0.43243456 0.56756544]\n",
      " [0.86160717 0.13839283]\n",
      " ...\n",
      " [0.5603337  0.4396663 ]\n",
      " [0.73905983 0.26094017]\n",
      " [0.77525296 0.22474704]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(full_y, final_model.predict(full_X)))\n",
    "print(model.predict_proba(full_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25c758-0e0f-444f-958d-ed18dab78b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
